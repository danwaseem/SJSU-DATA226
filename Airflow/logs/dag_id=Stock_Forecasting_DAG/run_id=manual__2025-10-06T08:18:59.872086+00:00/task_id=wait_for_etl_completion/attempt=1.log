[2025-10-06T08:19:10.719+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T08:19:10.750+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T08:19:10.776+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T08:19:10.778+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T08:19:10.810+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T08:19:10.833+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=554) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T08:19:10.859+0000] {standard_task_runner.py:72} INFO - Started process 557 to run task
[2025-10-06T08:19:10.877+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '33', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpztljqy2h']
[2025-10-06T08:19:10.880+0000] {standard_task_runner.py:105} INFO - Job 33: Subtask wait_for_etl_completion
[2025-10-06T08:19:11.180+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T08:19:11.590+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T08:19:11.642+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T08:19:11.665+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T08:19:11.692+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T08:19:11.812+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T08:19:11.885+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T08:19:11.886+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T08:19:11.927+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T08:19:11.959+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T08:19:11.976+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T08:21:17.364+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T08:21:17.409+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T08:21:17.429+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T08:21:17.430+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T08:21:17.458+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T08:21:17.482+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=623) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T08:21:17.483+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '34', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpy6viaiuc']
[2025-10-06T08:21:17.485+0000] {standard_task_runner.py:105} INFO - Job 34: Subtask wait_for_etl_completion
[2025-10-06T08:21:17.485+0000] {standard_task_runner.py:72} INFO - Started process 632 to run task
[2025-10-06T08:21:18.181+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T08:21:19.953+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T08:21:19.958+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T08:21:19.969+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T08:21:20.306+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T08:21:20.334+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T08:21:20.379+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T08:21:20.382+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T08:21:20.469+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T08:21:20.599+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T08:21:20.612+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T08:23:25.016+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T08:23:25.042+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T08:23:25.057+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T08:23:25.058+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T08:23:25.080+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T08:23:25.128+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=698) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T08:23:25.130+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '35', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpy1r_d5ug']
[2025-10-06T08:23:25.132+0000] {standard_task_runner.py:105} INFO - Job 35: Subtask wait_for_etl_completion
[2025-10-06T08:23:25.132+0000] {standard_task_runner.py:72} INFO - Started process 701 to run task
[2025-10-06T08:23:25.219+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T08:23:25.913+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T08:23:25.917+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T08:23:25.942+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T08:23:25.958+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T08:23:26.025+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T08:23:26.091+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T08:23:26.092+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T08:23:26.132+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T08:23:26.149+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T08:23:26.157+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T08:25:37.755+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T08:25:37.794+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T08:25:37.814+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T08:25:37.816+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T08:25:37.846+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T08:25:37.875+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=765) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T08:25:37.878+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '36', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp6e43q_nk']
[2025-10-06T08:25:37.880+0000] {standard_task_runner.py:72} INFO - Started process 770 to run task
[2025-10-06T08:25:37.881+0000] {standard_task_runner.py:105} INFO - Job 36: Subtask wait_for_etl_completion
[2025-10-06T08:25:38.053+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T08:25:38.249+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T08:25:38.253+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T08:25:38.258+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T08:25:38.273+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T08:25:38.293+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T08:25:38.335+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T08:25:38.336+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T08:25:38.372+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T08:25:38.391+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T08:25:38.400+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T08:27:43.464+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T08:27:43.494+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T08:27:43.507+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T08:27:43.508+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T08:27:43.531+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T08:27:43.551+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=829) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T08:27:43.551+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '37', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp2277bt1y']
[2025-10-06T08:27:43.553+0000] {standard_task_runner.py:72} INFO - Started process 832 to run task
[2025-10-06T08:27:43.554+0000] {standard_task_runner.py:105} INFO - Job 37: Subtask wait_for_etl_completion
[2025-10-06T08:27:43.650+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T08:27:43.818+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T08:27:43.822+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T08:27:43.827+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T08:27:43.846+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T08:27:43.869+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T08:27:43.926+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T08:27:43.930+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T08:27:43.958+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T08:27:43.979+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T08:27:43.988+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T08:40:58.580+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T08:40:58.626+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T08:40:58.648+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T08:40:58.649+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T08:40:58.685+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T08:40:58.734+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=862) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T08:40:58.738+0000] {standard_task_runner.py:72} INFO - Started process 869 to run task
[2025-10-06T08:40:58.736+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '38', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpyl9kdmgm']
[2025-10-06T08:40:58.741+0000] {standard_task_runner.py:105} INFO - Job 38: Subtask wait_for_etl_completion
[2025-10-06T08:40:59.102+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T08:40:59.544+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T08:40:59.547+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T08:40:59.554+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T08:40:59.581+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T08:40:59.617+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T08:40:59.679+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T08:40:59.683+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T08:40:59.730+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T08:40:59.754+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T08:40:59.767+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:11:58.980+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:11:59.109+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:11:59.176+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:11:59.181+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:11:59.280+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:11:59.325+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=912) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:11:59.333+0000] {standard_task_runner.py:72} INFO - Started process 917 to run task
[2025-10-06T09:11:59.329+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '39', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpmv7o4wi2']
[2025-10-06T09:11:59.342+0000] {standard_task_runner.py:105} INFO - Job 39: Subtask wait_for_etl_completion
[2025-10-06T09:11:59.892+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:12:00.697+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:12:00.708+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:12:00.723+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:12:00.779+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:12:00.855+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:12:01.045+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:12:01.050+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:12:01.174+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:12:01.569+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:12:01.726+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:14:16.101+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:14:16.206+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:14:16.258+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:14:16.264+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:14:16.352+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:14:16.404+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=973) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:14:16.405+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '40', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpd65ovgnf']
[2025-10-06T09:14:16.412+0000] {standard_task_runner.py:72} INFO - Started process 981 to run task
[2025-10-06T09:14:16.415+0000] {standard_task_runner.py:105} INFO - Job 40: Subtask wait_for_etl_completion
[2025-10-06T09:14:16.751+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:14:17.375+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:14:17.387+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:14:17.406+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:14:17.465+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:14:17.549+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:14:17.719+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:14:17.722+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:14:17.770+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:14:17.831+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:14:17.869+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:16:42.242+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:16:42.365+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:16:42.419+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:16:42.422+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:16:42.514+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:16:42.624+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=1036) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:16:42.634+0000] {standard_task_runner.py:72} INFO - Started process 1053 to run task
[2025-10-06T09:16:42.622+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '41', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpsthrswtn']
[2025-10-06T09:16:42.639+0000] {standard_task_runner.py:105} INFO - Job 41: Subtask wait_for_etl_completion
[2025-10-06T09:16:43.521+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:16:47.258+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:16:47.329+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:16:47.370+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:16:47.778+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:16:48.335+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:16:50.586+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:16:50.961+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:16:52.177+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:16:52.684+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:16:52.769+0000] {standard_task_runner.py:217} INFO - Process not found (most likely exited), stop collecting metrics
[2025-10-06T09:19:05.713+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:19:05.822+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:19:05.865+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:19:05.867+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:19:05.935+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:19:05.985+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=1106) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:19:05.987+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '42', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmprm17ihv_']
[2025-10-06T09:19:05.994+0000] {standard_task_runner.py:72} INFO - Started process 1123 to run task
[2025-10-06T09:19:05.994+0000] {standard_task_runner.py:105} INFO - Job 42: Subtask wait_for_etl_completion
[2025-10-06T09:19:06.319+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:19:07.611+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:19:07.620+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:19:07.643+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:19:07.729+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:19:07.820+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:19:07.986+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:19:07.990+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:19:08.076+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:19:08.158+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:19:08.211+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:21:22.327+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:21:22.420+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:21:22.461+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:21:22.464+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:21:22.573+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:21:22.640+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=1186) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:21:22.640+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '43', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpo8ezalpn']
[2025-10-06T09:21:22.646+0000] {standard_task_runner.py:72} INFO - Started process 1189 to run task
[2025-10-06T09:21:22.648+0000] {standard_task_runner.py:105} INFO - Job 43: Subtask wait_for_etl_completion
[2025-10-06T09:21:23.009+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:21:23.568+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:21:23.576+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:21:23.591+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:21:23.652+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:21:23.715+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:21:23.859+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:21:23.861+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:21:23.925+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:21:23.980+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:21:24.003+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:23:39.410+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:23:39.512+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:23:39.557+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:23:39.558+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:23:39.655+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:23:39.705+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '44', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmptv_w4s0m']
[2025-10-06T09:23:39.714+0000] {standard_task_runner.py:105} INFO - Job 44: Subtask wait_for_etl_completion
[2025-10-06T09:23:39.735+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=1248) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:23:39.745+0000] {standard_task_runner.py:72} INFO - Started process 1260 to run task
[2025-10-06T09:23:40.161+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:23:41.054+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:23:41.061+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:23:41.078+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:23:41.154+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:23:41.310+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:23:41.759+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:23:41.819+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:23:42.018+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:23:42.265+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:25:58.771+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:25:58.884+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:25:58.927+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:25:58.929+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:25:59.024+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:25:59.144+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=1320) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:25:59.147+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '45', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpr3dxktqa']
[2025-10-06T09:25:59.153+0000] {standard_task_runner.py:72} INFO - Started process 1325 to run task
[2025-10-06T09:25:59.154+0000] {standard_task_runner.py:105} INFO - Job 45: Subtask wait_for_etl_completion
[2025-10-06T09:25:59.430+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:26:00.263+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:26:00.270+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:26:00.281+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:26:00.322+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:26:00.375+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:26:00.506+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:26:00.509+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:26:00.594+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:26:00.678+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:26:00.709+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:28:13.264+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:28:13.365+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:28:13.406+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:28:13.409+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:28:13.468+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:28:13.505+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=1386) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:28:13.515+0000] {standard_task_runner.py:72} INFO - Started process 1392 to run task
[2025-10-06T09:28:13.521+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '46', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpd1nnx_4y']
[2025-10-06T09:28:13.529+0000] {standard_task_runner.py:105} INFO - Job 46: Subtask wait_for_etl_completion
[2025-10-06T09:28:13.836+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:28:14.436+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:28:14.453+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:28:14.463+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:28:14.507+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:28:14.618+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:28:14.848+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:28:14.852+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:28:14.897+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:28:14.954+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:28:14.980+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:30:27.891+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:30:27.972+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:30:28.020+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:30:28.024+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:30:28.085+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:30:28.127+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=1454) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:30:28.129+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '47', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpviwzwqjz']
[2025-10-06T09:30:28.132+0000] {standard_task_runner.py:72} INFO - Started process 1463 to run task
[2025-10-06T09:30:28.134+0000] {standard_task_runner.py:105} INFO - Job 47: Subtask wait_for_etl_completion
[2025-10-06T09:30:28.409+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:30:28.929+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:30:28.945+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:30:28.963+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:30:29.015+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:30:29.075+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:30:29.185+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:30:29.188+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:30:29.255+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:30:29.337+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:30:29.363+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:32:43.773+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:32:43.883+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:32:43.970+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:32:43.972+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:32:44.039+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:32:44.084+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=1524) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:32:44.084+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '48', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp2gc4qvyn']
[2025-10-06T09:32:44.090+0000] {standard_task_runner.py:72} INFO - Started process 1537 to run task
[2025-10-06T09:32:44.091+0000] {standard_task_runner.py:105} INFO - Job 48: Subtask wait_for_etl_completion
[2025-10-06T09:32:44.413+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:32:44.836+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:32:44.843+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:32:44.865+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:32:44.914+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:32:44.974+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:32:45.118+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:32:45.120+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:32:45.179+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:32:45.228+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:32:45.245+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:34:55.885+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:34:55.979+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:34:56.018+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:34:56.020+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:34:56.093+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:34:56.132+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=1593) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:34:56.133+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '49', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpp69dh96r']
[2025-10-06T09:34:56.137+0000] {standard_task_runner.py:72} INFO - Started process 1607 to run task
[2025-10-06T09:34:56.138+0000] {standard_task_runner.py:105} INFO - Job 49: Subtask wait_for_etl_completion
[2025-10-06T09:34:56.366+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:34:56.829+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:34:56.838+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:34:56.852+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:34:56.890+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:34:56.942+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:34:57.182+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:34:57.190+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:34:57.298+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:34:57.369+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:34:57.392+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:37:21.695+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:37:21.846+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:37:21.899+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:37:21.902+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:37:22.006+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:37:22.073+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=1665) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:37:22.067+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '50', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpzn8sa_mn']
[2025-10-06T09:37:22.084+0000] {standard_task_runner.py:105} INFO - Job 50: Subtask wait_for_etl_completion
[2025-10-06T09:37:22.083+0000] {standard_task_runner.py:72} INFO - Started process 1675 to run task
[2025-10-06T09:37:22.862+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:37:23.746+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:37:23.782+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:37:23.793+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:37:23.843+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:37:23.974+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:37:24.316+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:37:24.321+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:37:24.523+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:37:24.709+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:37:24.740+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:39:40.305+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:39:40.399+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:39:40.463+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:39:40.467+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:39:40.549+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:39:40.755+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '51', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpchi91vp7']
[2025-10-06T09:39:40.769+0000] {standard_task_runner.py:105} INFO - Job 51: Subtask wait_for_etl_completion
[2025-10-06T09:39:40.805+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=1735) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:39:40.835+0000] {standard_task_runner.py:72} INFO - Started process 1747 to run task
[2025-10-06T09:39:41.359+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:39:41.947+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:39:41.958+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:39:41.976+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:39:42.023+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:39:42.089+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:39:42.235+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:39:42.239+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:39:42.376+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:39:42.498+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:39:42.552+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:41:53.630+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:41:53.744+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:41:53.787+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:41:53.790+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:41:53.853+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:41:53.928+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '52', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpcdd9bu52']
[2025-10-06T09:41:53.951+0000] {standard_task_runner.py:105} INFO - Job 52: Subtask wait_for_etl_completion
[2025-10-06T09:41:53.948+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=1810) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:41:53.961+0000] {standard_task_runner.py:72} INFO - Started process 1813 to run task
[2025-10-06T09:41:54.232+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:41:54.637+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:41:54.643+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:41:54.653+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:41:54.693+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:41:54.744+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:41:54.853+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:41:54.856+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:41:54.913+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:41:54.966+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:44:06.346+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:44:06.421+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:44:06.458+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:44:06.460+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:44:06.523+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:44:06.591+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=1875) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:44:06.593+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '53', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp7uk9cknx']
[2025-10-06T09:44:06.598+0000] {standard_task_runner.py:72} INFO - Started process 1887 to run task
[2025-10-06T09:44:06.600+0000] {standard_task_runner.py:105} INFO - Job 53: Subtask wait_for_etl_completion
[2025-10-06T09:44:06.997+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:44:07.926+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:44:07.954+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:44:07.989+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:44:08.101+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:44:08.211+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:44:08.417+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:44:08.423+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:44:08.521+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:44:08.614+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:44:08.645+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:46:20.790+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:46:20.969+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:46:21.019+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:46:21.022+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:46:21.117+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:46:21.189+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '54', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp_zes3kjy']
[2025-10-06T09:46:21.190+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=1950) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:46:21.206+0000] {standard_task_runner.py:105} INFO - Job 54: Subtask wait_for_etl_completion
[2025-10-06T09:46:21.212+0000] {standard_task_runner.py:72} INFO - Started process 1953 to run task
[2025-10-06T09:46:21.810+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:46:22.350+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:46:22.360+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:46:22.488+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:46:22.656+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:46:22.854+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:46:23.060+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:46:23.086+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:46:23.171+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:46:23.477+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:46:23.507+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:48:35.222+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:48:35.324+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:48:35.371+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:48:35.374+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:48:35.464+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:48:35.528+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '55', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp4p67l6k0']
[2025-10-06T09:48:35.536+0000] {standard_task_runner.py:105} INFO - Job 55: Subtask wait_for_etl_completion
[2025-10-06T09:48:35.527+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=2013) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:48:35.544+0000] {standard_task_runner.py:72} INFO - Started process 2019 to run task
[2025-10-06T09:48:35.943+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:48:36.824+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:48:36.832+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:48:36.848+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:48:36.900+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:48:36.989+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:48:37.253+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:48:37.261+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:48:37.327+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:48:37.454+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:48:37.564+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:50:47.411+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:50:47.496+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:50:47.531+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:50:47.532+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:50:47.594+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:50:47.659+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=2082) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:50:47.669+0000] {standard_task_runner.py:72} INFO - Started process 2091 to run task
[2025-10-06T09:50:47.658+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '56', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpswx9n4v_']
[2025-10-06T09:50:47.682+0000] {standard_task_runner.py:105} INFO - Job 56: Subtask wait_for_etl_completion
[2025-10-06T09:50:48.101+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:50:48.684+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:50:48.690+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:50:48.707+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:50:48.755+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:50:48.812+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:50:48.915+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:50:48.917+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:50:48.994+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:50:49.036+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:50:49.059+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:52:58.983+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:52:59.067+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:52:59.117+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:52:59.120+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:52:59.229+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:52:59.289+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '57', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp1pjhlv8c']
[2025-10-06T09:52:59.328+0000] {standard_task_runner.py:105} INFO - Job 57: Subtask wait_for_etl_completion
[2025-10-06T09:52:59.302+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=2152) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:52:59.369+0000] {standard_task_runner.py:72} INFO - Started process 2158 to run task
[2025-10-06T09:52:59.976+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:53:00.689+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:53:00.714+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:53:00.772+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:53:00.875+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:53:00.961+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:53:01.409+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:53:01.413+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:53:01.549+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:53:01.611+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:53:01.684+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:55:26.435+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:55:26.687+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:55:26.759+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:55:26.763+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:55:27.051+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:55:27.142+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '58', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpgwf9ezl4']
[2025-10-06T09:55:27.153+0000] {standard_task_runner.py:105} INFO - Job 58: Subtask wait_for_etl_completion
[2025-10-06T09:55:27.174+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=2219) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:55:27.196+0000] {standard_task_runner.py:72} INFO - Started process 2232 to run task
[2025-10-06T09:55:27.792+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:55:29.004+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:55:29.012+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:55:29.059+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:55:29.130+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:55:29.268+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:55:29.458+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:55:29.461+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:55:29.595+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:55:29.702+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:55:29.742+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:57:44.489+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:57:44.601+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:57:44.665+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:57:44.669+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:57:44.837+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:57:44.933+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '59', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpe04vdm_m']
[2025-10-06T09:57:44.949+0000] {standard_task_runner.py:105} INFO - Job 59: Subtask wait_for_etl_completion
[2025-10-06T09:57:44.949+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=2291) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:57:44.958+0000] {standard_task_runner.py:72} INFO - Started process 2300 to run task
[2025-10-06T09:57:45.487+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:57:46.460+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:57:46.465+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:57:46.476+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:57:46.519+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:57:46.590+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:57:46.741+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:57:46.754+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:57:46.798+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:57:46.850+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:57:46.871+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T09:59:57.120+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T09:59:57.218+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:59:57.253+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T09:59:57.256+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T09:59:57.335+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T09:59:57.377+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=2360) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T09:59:57.379+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '60', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp2a3c1uvb']
[2025-10-06T09:59:57.384+0000] {standard_task_runner.py:72} INFO - Started process 2366 to run task
[2025-10-06T09:59:57.384+0000] {standard_task_runner.py:105} INFO - Job 60: Subtask wait_for_etl_completion
[2025-10-06T09:59:57.641+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T09:59:58.256+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T09:59:58.271+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T09:59:58.282+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T09:59:58.355+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T09:59:58.424+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T09:59:58.850+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T09:59:58.853+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T09:59:58.920+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T09:59:59.169+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T09:59:59.210+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:02:09.842+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:02:09.971+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:02:10.010+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:02:10.012+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:02:10.070+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:02:10.122+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=2422) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:02:10.119+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '61', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpl9ufgm67']
[2025-10-06T10:02:10.137+0000] {standard_task_runner.py:72} INFO - Started process 2437 to run task
[2025-10-06T10:02:10.140+0000] {standard_task_runner.py:105} INFO - Job 61: Subtask wait_for_etl_completion
[2025-10-06T10:02:10.445+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:02:10.985+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:02:10.997+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:02:11.010+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:02:11.084+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:02:11.173+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:02:11.349+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:02:11.353+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:02:11.447+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:02:11.489+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:02:11.546+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:04:21.545+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:04:21.645+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:04:21.693+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:04:21.695+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:04:21.770+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:04:21.818+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '62', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpzs4h2v9k']
[2025-10-06T10:04:21.821+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=2497) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:04:21.828+0000] {standard_task_runner.py:105} INFO - Job 62: Subtask wait_for_etl_completion
[2025-10-06T10:04:21.831+0000] {standard_task_runner.py:72} INFO - Started process 2505 to run task
[2025-10-06T10:04:22.091+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:04:22.716+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:04:22.727+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:04:22.737+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:04:22.904+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:04:23.000+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:04:23.487+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:04:23.490+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:04:23.680+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:04:23.823+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:04:23.859+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:06:37.515+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:06:37.639+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:06:37.689+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:06:37.690+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:06:37.779+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:06:37.825+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=2561) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:06:37.825+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '63', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp0we5benp']
[2025-10-06T10:06:37.831+0000] {standard_task_runner.py:72} INFO - Started process 2577 to run task
[2025-10-06T10:06:37.832+0000] {standard_task_runner.py:105} INFO - Job 63: Subtask wait_for_etl_completion
[2025-10-06T10:06:38.156+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:06:38.898+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:06:38.905+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:06:38.920+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:06:38.981+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:06:39.053+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:06:39.218+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:06:39.224+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:06:39.337+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:06:39.436+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:06:39.483+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:08:50.469+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:08:50.548+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:08:50.596+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:08:50.600+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:08:50.660+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:08:50.700+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '64', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpq_ma07un']
[2025-10-06T10:08:50.699+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=2635) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:08:50.705+0000] {standard_task_runner.py:105} INFO - Job 64: Subtask wait_for_etl_completion
[2025-10-06T10:08:50.708+0000] {standard_task_runner.py:72} INFO - Started process 2643 to run task
[2025-10-06T10:08:50.944+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:08:51.388+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:08:51.393+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:08:51.402+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:08:51.441+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:08:51.504+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:08:51.606+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:08:51.607+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:08:51.666+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:08:51.711+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:08:51.748+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:11:02.620+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:11:02.705+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:11:02.742+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:11:02.744+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:11:02.801+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:11:02.854+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=2701) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:11:02.854+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '65', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpw0a2e6qd']
[2025-10-06T10:11:02.861+0000] {standard_task_runner.py:105} INFO - Job 65: Subtask wait_for_etl_completion
[2025-10-06T10:11:02.860+0000] {standard_task_runner.py:72} INFO - Started process 2711 to run task
[2025-10-06T10:11:03.108+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:11:03.573+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:11:03.580+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:11:03.590+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:11:03.624+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:11:03.673+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:11:03.834+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:11:03.838+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:11:03.886+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:11:03.928+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:11:03.946+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:13:15.188+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:13:15.289+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:13:15.332+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:13:15.336+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:13:15.404+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:13:15.454+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=2766) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:13:15.458+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '66', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp7k_lcuw_']
[2025-10-06T10:13:15.465+0000] {standard_task_runner.py:105} INFO - Job 66: Subtask wait_for_etl_completion
[2025-10-06T10:13:15.462+0000] {standard_task_runner.py:72} INFO - Started process 2779 to run task
[2025-10-06T10:13:15.727+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:13:16.117+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:13:16.122+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:13:16.136+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:13:16.170+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:13:16.214+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:13:16.332+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:13:16.335+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:13:16.379+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:13:16.419+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:13:16.457+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:15:27.207+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:15:27.296+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:15:27.331+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:15:27.333+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:15:27.389+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:15:27.434+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=2840) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:15:27.436+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '67', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp4r_1vnzh']
[2025-10-06T10:15:27.440+0000] {standard_task_runner.py:72} INFO - Started process 2848 to run task
[2025-10-06T10:15:27.441+0000] {standard_task_runner.py:105} INFO - Job 67: Subtask wait_for_etl_completion
[2025-10-06T10:15:27.651+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:15:28.036+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:15:28.041+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:15:28.050+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:15:28.090+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:15:28.133+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:15:28.225+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:15:28.228+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:15:28.296+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:15:28.336+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:15:28.358+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:17:57.052+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:17:57.151+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:17:57.228+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:17:57.231+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:17:57.321+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:17:57.381+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '68', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpbrg7am6t']
[2025-10-06T10:17:57.391+0000] {standard_task_runner.py:105} INFO - Job 68: Subtask wait_for_etl_completion
[2025-10-06T10:17:57.382+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=2902) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:17:57.398+0000] {standard_task_runner.py:72} INFO - Started process 2918 to run task
[2025-10-06T10:17:57.669+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:17:58.329+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:17:58.336+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:17:58.350+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:17:58.421+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:17:58.485+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:17:58.648+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:17:58.651+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:17:58.721+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:17:58.804+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:17:58.828+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:20:11.432+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:20:11.519+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:20:11.582+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:20:11.584+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:20:11.655+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:20:11.696+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=2976) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:20:11.699+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '69', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpsu7x5cwe']
[2025-10-06T10:20:11.706+0000] {standard_task_runner.py:105} INFO - Job 69: Subtask wait_for_etl_completion
[2025-10-06T10:20:11.704+0000] {standard_task_runner.py:72} INFO - Started process 2982 to run task
[2025-10-06T10:20:12.038+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:20:12.799+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:20:12.805+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:20:12.820+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:20:12.874+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:20:12.966+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:20:13.080+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:20:13.082+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:20:13.181+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:20:13.252+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:20:13.313+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:22:30.087+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:22:30.223+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:22:30.314+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:22:30.319+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:22:30.465+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:22:30.537+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=3043) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:22:30.554+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '70', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpfuo6cau4']
[2025-10-06T10:22:30.560+0000] {standard_task_runner.py:72} INFO - Started process 3057 to run task
[2025-10-06T10:22:30.566+0000] {standard_task_runner.py:105} INFO - Job 70: Subtask wait_for_etl_completion
[2025-10-06T10:22:31.420+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:22:32.105+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:22:32.111+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:22:32.120+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:22:32.166+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:22:32.239+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:22:32.405+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:22:32.407+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:22:32.497+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:22:32.606+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:22:32.629+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:24:45.196+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:24:45.415+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:24:45.530+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:24:45.536+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:24:45.660+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:24:45.717+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=3116) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:24:45.728+0000] {standard_task_runner.py:72} INFO - Started process 3125 to run task
[2025-10-06T10:24:45.764+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '71', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp_7r15a5e']
[2025-10-06T10:24:45.774+0000] {standard_task_runner.py:105} INFO - Job 71: Subtask wait_for_etl_completion
[2025-10-06T10:24:46.458+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:24:47.432+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:24:47.440+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:24:47.481+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:24:47.557+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:24:47.615+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:24:47.808+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:24:47.811+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:24:47.862+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:24:47.918+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:24:47.939+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:27:00.670+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:27:00.822+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:27:00.870+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:27:00.873+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:27:00.982+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:27:01.031+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '72', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpy_rs5dak']
[2025-10-06T10:27:01.032+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=3184) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:27:01.043+0000] {standard_task_runner.py:105} INFO - Job 72: Subtask wait_for_etl_completion
[2025-10-06T10:27:01.047+0000] {standard_task_runner.py:72} INFO - Started process 3190 to run task
[2025-10-06T10:27:01.327+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:27:01.822+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:27:01.827+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:27:01.837+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:27:01.890+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:27:01.942+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:27:02.090+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:27:02.096+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:27:02.155+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:27:02.197+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:27:02.250+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:29:13.170+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:29:13.260+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:29:13.323+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:29:13.333+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:29:13.430+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:29:13.469+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=3252) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:29:13.470+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '73', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp_sk9g5_s']
[2025-10-06T10:29:13.478+0000] {standard_task_runner.py:72} INFO - Started process 3266 to run task
[2025-10-06T10:29:13.479+0000] {standard_task_runner.py:105} INFO - Job 73: Subtask wait_for_etl_completion
[2025-10-06T10:29:13.962+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:29:14.503+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:29:14.510+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:29:14.522+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:29:14.567+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:29:14.628+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:29:14.732+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:29:14.734+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:29:14.807+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:29:14.861+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:29:14.968+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:31:25.025+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:31:25.100+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:31:25.137+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:31:25.139+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:31:25.194+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:31:25.229+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=3324) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:31:25.230+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '74', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp12rddq55']
[2025-10-06T10:31:25.235+0000] {standard_task_runner.py:72} INFO - Started process 3330 to run task
[2025-10-06T10:31:25.235+0000] {standard_task_runner.py:105} INFO - Job 74: Subtask wait_for_etl_completion
[2025-10-06T10:31:25.458+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:31:26.313+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:31:26.318+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:31:26.327+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:31:26.368+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:31:26.424+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:31:26.519+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:31:26.522+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:31:26.581+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:31:26.621+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:31:26.637+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:33:41.003+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:33:41.249+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:33:41.388+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:33:41.394+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:33:41.575+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:33:41.614+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=3393) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:33:41.615+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '75', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpuhkg1b18']
[2025-10-06T10:33:41.622+0000] {standard_task_runner.py:72} INFO - Started process 3407 to run task
[2025-10-06T10:33:41.623+0000] {standard_task_runner.py:105} INFO - Job 75: Subtask wait_for_etl_completion
[2025-10-06T10:33:41.903+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:33:42.345+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:33:42.353+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:33:42.377+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:33:42.422+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:33:42.491+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:33:42.665+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:33:42.667+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:33:42.721+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:33:42.779+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:33:42.826+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:35:57.455+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:35:57.552+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:35:57.608+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:35:57.610+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:35:57.668+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:35:57.701+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=3462) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:35:57.703+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '76', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmperko9jzt']
[2025-10-06T10:35:57.709+0000] {standard_task_runner.py:105} INFO - Job 76: Subtask wait_for_etl_completion
[2025-10-06T10:35:57.707+0000] {standard_task_runner.py:72} INFO - Started process 3475 to run task
[2025-10-06T10:35:57.991+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:35:58.518+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:35:58.531+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:35:58.551+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:35:58.595+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:35:58.646+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:35:58.763+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:35:58.766+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:35:58.839+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:35:58.885+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:35:58.901+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:38:09.875+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:38:09.964+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:38:10.004+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:38:10.006+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:38:10.084+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:38:10.131+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '77', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmppmy7hish']
[2025-10-06T10:38:10.130+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=3531) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:38:10.137+0000] {standard_task_runner.py:105} INFO - Job 77: Subtask wait_for_etl_completion
[2025-10-06T10:38:10.138+0000] {standard_task_runner.py:72} INFO - Started process 3537 to run task
[2025-10-06T10:38:10.362+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:38:10.848+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:38:10.854+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:38:10.872+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:38:10.982+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:38:11.062+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:38:11.224+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:38:11.241+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:38:11.307+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:38:11.401+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:38:11.433+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:40:24.373+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:40:24.475+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:40:24.532+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:40:24.540+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:40:24.728+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:40:24.788+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '78', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmps5d12d6n']
[2025-10-06T10:40:24.796+0000] {standard_task_runner.py:105} INFO - Job 78: Subtask wait_for_etl_completion
[2025-10-06T10:40:24.796+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=3597) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:40:24.801+0000] {standard_task_runner.py:72} INFO - Started process 3611 to run task
[2025-10-06T10:40:25.207+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:40:25.799+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:40:25.805+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:40:25.817+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:40:25.859+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:40:25.924+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:40:26.165+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:40:26.176+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:40:26.287+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:40:26.416+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:40:26.497+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:42:35.596+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:42:35.666+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:42:35.720+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:42:35.722+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:42:35.784+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:42:35.818+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=3668) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:42:35.819+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '79', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp93jc_1bw']
[2025-10-06T10:42:35.825+0000] {standard_task_runner.py:72} INFO - Started process 3671 to run task
[2025-10-06T10:42:35.825+0000] {standard_task_runner.py:105} INFO - Job 79: Subtask wait_for_etl_completion
[2025-10-06T10:42:36.107+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:42:36.876+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:42:36.889+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:42:36.896+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:42:36.932+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:42:36.977+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:42:37.072+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:42:37.075+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:42:37.108+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:42:37.152+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:42:37.179+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:44:46.862+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:44:46.940+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:44:46.970+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:44:46.972+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:44:47.026+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:44:47.057+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=3737) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:44:47.059+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '80', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpgvzmzfwc']
[2025-10-06T10:44:47.064+0000] {standard_task_runner.py:105} INFO - Job 80: Subtask wait_for_etl_completion
[2025-10-06T10:44:47.063+0000] {standard_task_runner.py:72} INFO - Started process 3740 to run task
[2025-10-06T10:44:47.274+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:44:47.620+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:44:47.629+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:44:47.649+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:44:47.699+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:44:47.743+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:44:47.841+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:44:47.843+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:44:47.888+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:44:47.931+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:44:47.951+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:47:18.283+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:47:18.788+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:47:18.964+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:47:18.966+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:47:19.189+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:47:19.280+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=3799) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:47:19.286+0000] {standard_task_runner.py:72} INFO - Started process 3817 to run task
[2025-10-06T10:47:19.277+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '81', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp1naikghi']
[2025-10-06T10:47:19.295+0000] {standard_task_runner.py:105} INFO - Job 81: Subtask wait_for_etl_completion
[2025-10-06T10:47:20.096+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:47:21.978+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:47:21.992+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:47:22.080+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:47:22.253+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:47:22.583+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:47:23.177+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:47:23.185+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:47:23.420+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:47:23.835+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:47:24.330+0000] {standard_task_runner.py:217} INFO - Process not found (most likely exited), stop collecting metrics
[2025-10-06T10:49:37.537+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:49:37.679+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:49:37.728+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:49:37.731+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:49:37.814+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:49:37.861+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=3872) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:49:37.864+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '82', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpnrezw9bn']
[2025-10-06T10:49:37.869+0000] {standard_task_runner.py:105} INFO - Job 82: Subtask wait_for_etl_completion
[2025-10-06T10:49:37.868+0000] {standard_task_runner.py:72} INFO - Started process 3888 to run task
[2025-10-06T10:49:38.182+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:49:38.834+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:49:38.841+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:49:38.856+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:49:38.912+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:49:38.980+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:49:39.156+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:49:39.158+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:49:39.224+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:49:39.308+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:49:39.337+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:51:50.793+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:51:50.885+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:51:50.930+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:51:50.934+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:51:51.027+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:51:51.078+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=3946) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:51:51.085+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '83', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpdqqbynrz']
[2025-10-06T10:51:51.087+0000] {standard_task_runner.py:72} INFO - Started process 3954 to run task
[2025-10-06T10:51:51.093+0000] {standard_task_runner.py:105} INFO - Job 83: Subtask wait_for_etl_completion
[2025-10-06T10:51:51.363+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:51:51.779+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:51:51.790+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:51:51.809+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:51:51.854+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:51:51.916+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:51:52.020+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:51:52.022+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:51:52.082+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:51:52.245+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:51:52.297+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:54:09.084+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:54:09.310+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:54:09.381+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:54:09.384+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:54:09.534+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:54:09.647+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=4010) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:54:09.665+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '84', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp1lb3mf8i']
[2025-10-06T10:54:09.676+0000] {standard_task_runner.py:72} INFO - Started process 4026 to run task
[2025-10-06T10:54:09.675+0000] {standard_task_runner.py:105} INFO - Job 84: Subtask wait_for_etl_completion
[2025-10-06T10:54:11.223+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:54:12.471+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:54:12.511+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:54:12.537+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:54:12.730+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:54:12.845+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:54:13.353+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:54:13.358+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:54:13.468+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:54:13.679+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:54:13.727+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:56:31.354+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:56:31.503+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:56:31.559+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:56:31.563+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:56:31.669+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:56:31.729+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '85', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpmq_2nsgw']
[2025-10-06T10:56:31.744+0000] {standard_task_runner.py:105} INFO - Job 85: Subtask wait_for_etl_completion
[2025-10-06T10:56:31.745+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=4081) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:56:31.776+0000] {standard_task_runner.py:72} INFO - Started process 4092 to run task
[2025-10-06T10:56:32.147+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:56:33.788+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:56:33.808+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:56:33.965+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:56:34.457+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:56:34.728+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:56:35.115+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:56:35.121+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:56:35.254+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:56:35.483+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:56:35.537+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T10:58:47.590+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T10:58:47.703+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:58:47.749+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T10:58:47.752+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T10:58:47.832+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T10:58:47.880+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=4150) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T10:58:47.882+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '86', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpfxbu4d_g']
[2025-10-06T10:58:47.890+0000] {standard_task_runner.py:72} INFO - Started process 4162 to run task
[2025-10-06T10:58:47.890+0000] {standard_task_runner.py:105} INFO - Job 86: Subtask wait_for_etl_completion
[2025-10-06T10:58:48.190+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T10:58:48.716+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T10:58:48.723+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T10:58:48.746+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T10:58:48.800+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T10:58:48.882+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T10:58:49.027+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T10:58:49.029+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T10:58:49.105+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T10:58:49.157+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T10:58:49.182+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:01:00.256+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:01:00.363+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:01:00.424+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:01:00.426+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:01:00.497+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:01:00.543+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=4225) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:01:00.545+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '87', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp214w583n']
[2025-10-06T11:01:00.550+0000] {standard_task_runner.py:72} INFO - Started process 4233 to run task
[2025-10-06T11:01:00.551+0000] {standard_task_runner.py:105} INFO - Job 87: Subtask wait_for_etl_completion
[2025-10-06T11:01:00.804+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:01:01.184+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:01:01.188+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:01:01.197+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:01:01.236+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:01:01.303+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:01:01.402+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:01:01.404+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:01:01.459+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:01:01.505+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:01:01.527+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:03:17.658+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:03:17.794+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:03:17.847+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:03:17.849+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:03:17.927+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:03:17.967+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=4289) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:03:17.969+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '88', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpwk60vn49']
[2025-10-06T11:03:17.976+0000] {standard_task_runner.py:72} INFO - Started process 4309 to run task
[2025-10-06T11:03:17.978+0000] {standard_task_runner.py:105} INFO - Job 88: Subtask wait_for_etl_completion
[2025-10-06T11:03:18.310+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:03:18.854+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:03:18.861+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:03:18.877+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:03:18.938+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:03:19.001+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:03:19.136+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:03:19.138+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:03:19.204+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:03:19.278+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:03:19.298+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:05:31.238+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:05:31.347+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:05:31.394+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:05:31.395+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:05:31.455+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:05:31.496+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=4365) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:05:31.498+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '89', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpasvfsoqg']
[2025-10-06T11:05:31.501+0000] {standard_task_runner.py:72} INFO - Started process 4373 to run task
[2025-10-06T11:05:31.503+0000] {standard_task_runner.py:105} INFO - Job 89: Subtask wait_for_etl_completion
[2025-10-06T11:05:31.723+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:05:32.200+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:05:32.209+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:05:32.224+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:05:32.260+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:05:32.306+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:05:32.417+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:05:32.419+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:05:32.496+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:05:32.548+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:05:32.575+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:07:44.898+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:07:44.972+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:07:45.009+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:07:45.011+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:07:45.068+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:07:45.102+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=4437) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:07:45.108+0000] {standard_task_runner.py:72} INFO - Started process 4442 to run task
[2025-10-06T11:07:45.105+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '90', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpx1nxu71t']
[2025-10-06T11:07:45.116+0000] {standard_task_runner.py:105} INFO - Job 90: Subtask wait_for_etl_completion
[2025-10-06T11:07:45.390+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:07:45.836+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:07:45.841+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:07:45.854+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:07:45.895+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:07:45.952+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:07:46.195+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:07:46.197+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:07:46.271+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:07:46.349+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:07:46.392+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:09:58.607+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:09:58.679+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:09:58.714+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:09:58.716+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:09:58.773+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:09:58.813+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=4501) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:09:58.815+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '91', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpnwr_9que']
[2025-10-06T11:09:58.823+0000] {standard_task_runner.py:72} INFO - Started process 4518 to run task
[2025-10-06T11:09:58.826+0000] {standard_task_runner.py:105} INFO - Job 91: Subtask wait_for_etl_completion
[2025-10-06T11:09:59.070+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:09:59.581+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:09:59.587+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:09:59.598+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:09:59.647+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:09:59.706+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:09:59.808+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:09:59.810+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:09:59.851+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:09:59.917+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:09:59.944+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:12:09.740+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:12:09.806+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:12:09.838+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:12:09.840+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:12:09.891+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:12:09.921+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '92', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpbuzrlj68']
[2025-10-06T11:12:09.927+0000] {standard_task_runner.py:105} INFO - Job 92: Subtask wait_for_etl_completion
[2025-10-06T11:12:09.922+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=4579) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:12:09.932+0000] {standard_task_runner.py:72} INFO - Started process 4582 to run task
[2025-10-06T11:12:10.154+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:12:10.522+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:12:10.527+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:12:10.539+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:12:10.569+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:12:10.616+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:12:10.716+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:12:10.718+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:12:10.795+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:12:10.842+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:12:10.858+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:14:21.495+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:14:21.567+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:14:21.611+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:14:21.613+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:14:21.698+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:14:21.746+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '93', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpfz6wu86w']
[2025-10-06T11:14:21.746+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=4647) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:14:21.752+0000] {standard_task_runner.py:105} INFO - Job 93: Subtask wait_for_etl_completion
[2025-10-06T11:14:21.753+0000] {standard_task_runner.py:72} INFO - Started process 4650 to run task
[2025-10-06T11:14:21.972+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:14:22.371+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:14:22.379+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:14:22.396+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:14:22.443+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:14:22.490+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:14:22.595+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:14:22.598+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:14:22.657+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:14:22.703+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:14:22.719+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:16:34.810+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:16:35.015+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:16:35.068+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:16:35.070+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:16:35.249+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:16:35.360+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '94', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpqhrg2ssd']
[2025-10-06T11:16:35.369+0000] {standard_task_runner.py:105} INFO - Job 94: Subtask wait_for_etl_completion
[2025-10-06T11:16:35.403+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=4714) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:16:35.418+0000] {standard_task_runner.py:72} INFO - Started process 4725 to run task
[2025-10-06T11:16:35.918+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:16:36.369+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:16:36.378+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:16:36.407+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:16:36.454+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:16:36.509+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:16:36.610+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:16:36.612+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:16:36.686+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:16:36.730+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:16:36.753+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:18:47.514+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:18:47.585+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:18:47.624+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:18:47.627+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:18:47.680+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:18:47.734+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=4785) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:18:47.736+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '95', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpcosdx7ha']
[2025-10-06T11:18:47.741+0000] {standard_task_runner.py:72} INFO - Started process 4788 to run task
[2025-10-06T11:18:47.743+0000] {standard_task_runner.py:105} INFO - Job 95: Subtask wait_for_etl_completion
[2025-10-06T11:18:48.024+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:18:48.414+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:18:48.423+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:18:48.433+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:18:48.472+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:18:48.520+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:18:48.627+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:18:48.629+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:18:48.702+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:18:48.768+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:18:48.791+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:21:00.034+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:21:00.174+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:21:00.214+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:21:00.217+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:21:00.329+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:21:00.375+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=4854) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:21:00.376+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '96', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp1k9vvb5t']
[2025-10-06T11:21:00.381+0000] {standard_task_runner.py:72} INFO - Started process 4857 to run task
[2025-10-06T11:21:00.382+0000] {standard_task_runner.py:105} INFO - Job 96: Subtask wait_for_etl_completion
[2025-10-06T11:21:00.654+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:21:01.141+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:21:01.145+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:21:01.159+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:21:01.192+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:21:01.240+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:21:01.340+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:21:01.342+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:21:01.387+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:21:01.459+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:21:01.478+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:23:11.035+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:23:11.105+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:23:11.136+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:23:11.138+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:23:11.190+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:23:11.223+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=4921) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:23:11.224+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '97', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp7sel9p1u']
[2025-10-06T11:23:11.229+0000] {standard_task_runner.py:105} INFO - Job 97: Subtask wait_for_etl_completion
[2025-10-06T11:23:11.228+0000] {standard_task_runner.py:72} INFO - Started process 4932 to run task
[2025-10-06T11:23:11.436+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:23:11.786+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:23:11.792+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:23:11.800+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:23:11.847+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:23:11.896+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:23:11.993+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:23:11.996+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:23:12.047+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:23:12.087+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:23:12.111+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:25:21.987+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:25:22.075+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:25:22.121+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:25:22.124+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:25:22.188+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:25:22.237+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '98', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpqrkbyual']
[2025-10-06T11:25:22.235+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=4993) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:25:22.247+0000] {standard_task_runner.py:105} INFO - Job 98: Subtask wait_for_etl_completion
[2025-10-06T11:25:22.250+0000] {standard_task_runner.py:72} INFO - Started process 4999 to run task
[2025-10-06T11:25:22.787+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:25:23.588+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:25:23.619+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:25:23.635+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:25:23.768+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:25:23.884+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:25:24.163+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:25:24.169+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:25:24.323+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:25:24.411+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:25:24.432+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:27:33.233+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:27:33.335+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:27:33.375+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:27:33.377+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:27:33.476+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:27:33.523+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=5061) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:27:33.534+0000] {standard_task_runner.py:72} INFO - Started process 5064 to run task
[2025-10-06T11:27:33.563+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '99', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpxw8xbbjx']
[2025-10-06T11:27:33.583+0000] {standard_task_runner.py:105} INFO - Job 99: Subtask wait_for_etl_completion
[2025-10-06T11:27:33.975+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:27:34.677+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:27:34.681+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:27:34.691+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:27:34.741+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:27:34.800+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:27:35.043+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:27:35.051+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:27:35.122+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:27:35.181+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:27:35.202+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:29:44.407+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:29:44.495+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:29:44.532+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:29:44.534+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:29:44.591+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:29:44.627+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=5129) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:29:44.627+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '100', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpsasi90z4']
[2025-10-06T11:29:44.632+0000] {standard_task_runner.py:72} INFO - Started process 5138 to run task
[2025-10-06T11:29:44.633+0000] {standard_task_runner.py:105} INFO - Job 100: Subtask wait_for_etl_completion
[2025-10-06T11:29:44.876+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:29:45.246+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:29:45.251+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:29:45.259+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:29:45.294+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:29:45.341+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:29:45.435+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:29:45.437+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:29:45.490+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:29:45.534+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:29:45.550+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:31:55.748+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:31:55.839+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:31:55.888+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:31:55.889+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:31:55.955+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:31:55.996+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=5193) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:31:56.001+0000] {standard_task_runner.py:72} INFO - Started process 5202 to run task
[2025-10-06T11:31:55.999+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '101', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpxy07n07g']
[2025-10-06T11:31:56.005+0000] {standard_task_runner.py:105} INFO - Job 101: Subtask wait_for_etl_completion
[2025-10-06T11:31:56.268+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:31:56.815+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:31:56.825+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:31:56.843+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:31:56.900+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:31:56.967+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:31:57.131+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:31:57.138+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:31:57.222+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:31:57.335+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:34:08.504+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:34:08.596+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:34:08.640+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:34:08.643+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:34:08.712+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:34:08.766+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=5268) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:34:08.767+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '102', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpeqnshjo5']
[2025-10-06T11:34:08.774+0000] {standard_task_runner.py:72} INFO - Started process 5274 to run task
[2025-10-06T11:34:08.775+0000] {standard_task_runner.py:105} INFO - Job 102: Subtask wait_for_etl_completion
[2025-10-06T11:34:09.074+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:34:09.804+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:34:09.815+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:34:09.830+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:34:09.895+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:34:09.953+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:34:10.057+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:34:10.060+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:34:10.142+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:34:10.194+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:34:10.216+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:36:20.797+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:36:21.009+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:36:21.049+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:36:21.052+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:36:21.126+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:36:21.158+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=5336) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:36:21.159+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '103', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpv0tuv7pp']
[2025-10-06T11:36:21.167+0000] {standard_task_runner.py:105} INFO - Job 103: Subtask wait_for_etl_completion
[2025-10-06T11:36:21.166+0000] {standard_task_runner.py:72} INFO - Started process 5351 to run task
[2025-10-06T11:36:21.376+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:36:21.744+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:36:21.749+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:36:21.757+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:36:21.797+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:36:21.859+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:36:21.998+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:36:22.005+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:36:22.078+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:36:22.126+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:36:22.150+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:38:39.310+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:38:39.748+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:38:39.924+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:38:39.945+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:38:40.212+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:38:40.489+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=5407) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:38:40.503+0000] {standard_task_runner.py:72} INFO - Started process 5418 to run task
[2025-10-06T11:38:40.499+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '104', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp4dmv3tgp']
[2025-10-06T11:38:40.512+0000] {standard_task_runner.py:105} INFO - Job 104: Subtask wait_for_etl_completion
[2025-10-06T11:38:40.818+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:38:41.540+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:38:41.553+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:38:41.566+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:38:41.619+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:38:41.703+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:38:41.817+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:38:41.825+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:38:41.902+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:38:42.134+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:38:42.169+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:40:52.424+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:40:52.579+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:40:52.620+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:40:52.622+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:40:52.694+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:40:52.738+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '105', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp655oqcth']
[2025-10-06T11:40:52.744+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=5479) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:40:52.747+0000] {standard_task_runner.py:105} INFO - Job 105: Subtask wait_for_etl_completion
[2025-10-06T11:40:52.749+0000] {standard_task_runner.py:72} INFO - Started process 5484 to run task
[2025-10-06T11:40:53.006+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:40:53.454+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:40:53.458+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:40:53.470+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:40:53.527+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:40:53.576+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:40:53.710+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:40:53.711+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:40:53.786+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:40:53.843+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:40:53.868+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:43:09.325+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:43:09.510+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:43:09.651+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:43:09.653+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:43:09.908+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:43:09.989+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '106', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpceee4zal']
[2025-10-06T11:43:09.989+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=5542) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:43:10.000+0000] {standard_task_runner.py:72} INFO - Started process 5557 to run task
[2025-10-06T11:43:09.997+0000] {standard_task_runner.py:105} INFO - Job 106: Subtask wait_for_etl_completion
[2025-10-06T11:43:10.576+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:43:11.093+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:43:11.101+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:43:11.111+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:43:11.183+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:43:11.243+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:43:11.377+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:43:11.381+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:43:11.451+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:43:11.504+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:43:11.523+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:45:25.164+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:45:25.265+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:45:25.314+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:45:25.316+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:45:25.400+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:45:25.444+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=5618) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:45:25.445+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '107', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpiv_p7l9c']
[2025-10-06T11:45:25.452+0000] {standard_task_runner.py:72} INFO - Started process 5621 to run task
[2025-10-06T11:45:25.453+0000] {standard_task_runner.py:105} INFO - Job 107: Subtask wait_for_etl_completion
[2025-10-06T11:45:25.809+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:45:26.420+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:45:26.428+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:45:26.443+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:45:26.534+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:45:26.664+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:45:26.852+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:45:26.867+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:45:26.951+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:45:27.018+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:45:27.051+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:47:49.722+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:47:49.858+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:47:49.909+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:47:49.911+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:47:50.021+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:47:50.078+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=5677) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:47:50.080+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '108', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp7irolm3_']
[2025-10-06T11:47:50.089+0000] {standard_task_runner.py:72} INFO - Started process 5694 to run task
[2025-10-06T11:47:50.090+0000] {standard_task_runner.py:105} INFO - Job 108: Subtask wait_for_etl_completion
[2025-10-06T11:47:50.418+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:47:51.644+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:47:51.658+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:47:51.676+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:47:51.808+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:47:52.024+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:47:52.185+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:47:52.189+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:47:52.261+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:47:52.329+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:47:52.362+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:50:03.525+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:50:03.635+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:50:03.692+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:50:03.695+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:50:03.839+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:50:03.907+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '109', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp_ial_ouo']
[2025-10-06T11:50:03.917+0000] {standard_task_runner.py:105} INFO - Job 109: Subtask wait_for_etl_completion
[2025-10-06T11:50:03.914+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=5757) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:50:03.919+0000] {standard_task_runner.py:72} INFO - Started process 5760 to run task
[2025-10-06T11:50:04.191+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:50:04.729+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:50:04.735+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:50:04.745+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:50:04.788+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:50:04.843+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:50:04.977+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:50:04.979+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:50:05.033+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:50:05.087+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:50:05.130+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:52:18.065+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:52:18.148+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:52:18.191+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:52:18.193+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:52:18.262+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:52:18.296+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=5823) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:52:18.297+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '110', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmphyb14sqh']
[2025-10-06T11:52:18.303+0000] {standard_task_runner.py:72} INFO - Started process 5834 to run task
[2025-10-06T11:52:18.305+0000] {standard_task_runner.py:105} INFO - Job 110: Subtask wait_for_etl_completion
[2025-10-06T11:52:18.551+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:52:19.068+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:52:19.074+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:52:19.085+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:52:19.176+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:52:19.267+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:52:19.420+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:52:19.422+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:52:19.499+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:52:19.555+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:52:19.585+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:54:49.535+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:54:49.769+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:54:49.875+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:54:49.878+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:54:50.017+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:54:50.128+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=5896) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:54:50.144+0000] {standard_task_runner.py:72} INFO - Started process 5915 to run task
[2025-10-06T11:54:50.139+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '111', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpattfb843']
[2025-10-06T11:54:50.152+0000] {standard_task_runner.py:105} INFO - Job 111: Subtask wait_for_etl_completion
[2025-10-06T11:54:50.722+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:54:52.485+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:54:52.498+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:54:52.513+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:54:52.567+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:54:52.659+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:54:52.834+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:54:52.840+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:54:52.969+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:54:53.044+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:54:53.075+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:57:09.134+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:57:09.298+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:57:09.352+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:57:09.354+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:57:09.441+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:57:09.532+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=5968) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:57:09.534+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '112', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpf4btvueg']
[2025-10-06T11:57:09.543+0000] {standard_task_runner.py:105} INFO - Job 112: Subtask wait_for_etl_completion
[2025-10-06T11:57:09.542+0000] {standard_task_runner.py:72} INFO - Started process 5978 to run task
[2025-10-06T11:57:09.894+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:57:10.752+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:57:10.772+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:57:10.785+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:57:10.838+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:57:10.921+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:57:11.344+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:57:11.366+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:57:11.469+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:57:11.716+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T11:59:24.931+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T11:59:25.040+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:59:25.152+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T11:59:25.155+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T11:59:25.268+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T11:59:25.313+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '113', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpmlnl8au5']
[2025-10-06T11:59:25.320+0000] {standard_task_runner.py:105} INFO - Job 113: Subtask wait_for_etl_completion
[2025-10-06T11:59:25.310+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=6034) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T11:59:25.328+0000] {standard_task_runner.py:72} INFO - Started process 6051 to run task
[2025-10-06T11:59:25.589+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T11:59:26.058+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T11:59:26.064+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T11:59:26.078+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T11:59:26.114+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T11:59:26.161+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T11:59:26.264+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T11:59:26.267+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T11:59:26.318+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T11:59:26.365+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T11:59:26.396+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T12:01:38.331+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T12:01:38.416+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:01:38.467+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:01:38.470+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T12:01:38.559+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T12:01:38.625+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=6111) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T12:01:38.623+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '114', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpj05z7v15']
[2025-10-06T12:01:38.631+0000] {standard_task_runner.py:72} INFO - Started process 6116 to run task
[2025-10-06T12:01:38.632+0000] {standard_task_runner.py:105} INFO - Job 114: Subtask wait_for_etl_completion
[2025-10-06T12:01:38.878+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T12:01:39.336+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T12:01:39.345+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T12:01:39.354+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T12:01:39.392+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T12:01:39.442+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T12:01:39.579+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T12:01:39.582+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T12:01:39.641+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T12:01:39.694+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T12:01:39.737+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T12:03:49.093+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T12:03:49.163+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:03:49.196+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:03:49.198+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T12:03:49.246+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T12:03:49.298+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '115', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpv_pnutn9']
[2025-10-06T12:03:49.301+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=6181) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T12:03:49.306+0000] {standard_task_runner.py:105} INFO - Job 115: Subtask wait_for_etl_completion
[2025-10-06T12:03:49.308+0000] {standard_task_runner.py:72} INFO - Started process 6186 to run task
[2025-10-06T12:03:49.527+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T12:03:49.903+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T12:03:49.908+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T12:03:49.916+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T12:03:49.978+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T12:03:50.033+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T12:03:50.119+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T12:03:50.122+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T12:03:50.181+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T12:03:50.217+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T12:03:50.238+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T12:05:58.562+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T12:05:58.632+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:05:58.664+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:05:58.666+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T12:05:58.717+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T12:05:58.756+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=6247) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T12:05:58.757+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '116', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpnwz65etw']
[2025-10-06T12:05:58.765+0000] {standard_task_runner.py:105} INFO - Job 116: Subtask wait_for_etl_completion
[2025-10-06T12:05:58.764+0000] {standard_task_runner.py:72} INFO - Started process 6253 to run task
[2025-10-06T12:05:59.061+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T12:05:59.449+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T12:05:59.457+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T12:05:59.470+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T12:05:59.509+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T12:05:59.558+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T12:05:59.646+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T12:05:59.649+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T12:05:59.704+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T12:05:59.763+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T12:05:59.782+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T12:08:08.159+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T12:08:08.228+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:08:08.270+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:08:08.272+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T12:08:08.325+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T12:08:08.359+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=6317) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T12:08:08.361+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '117', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpzgtqk1tw']
[2025-10-06T12:08:08.364+0000] {standard_task_runner.py:72} INFO - Started process 6326 to run task
[2025-10-06T12:08:08.365+0000] {standard_task_runner.py:105} INFO - Job 117: Subtask wait_for_etl_completion
[2025-10-06T12:08:08.556+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T12:08:08.885+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T12:08:08.890+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T12:08:08.899+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T12:08:08.946+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T12:08:09.009+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T12:08:09.109+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T12:08:09.111+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T12:08:09.177+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T12:08:09.216+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T12:08:09.231+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T12:10:18.252+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T12:10:18.324+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:10:18.360+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:10:18.362+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T12:10:18.419+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T12:10:18.454+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=6390) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T12:10:18.455+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '118', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp7iert17b']
[2025-10-06T12:10:18.460+0000] {standard_task_runner.py:105} INFO - Job 118: Subtask wait_for_etl_completion
[2025-10-06T12:10:18.458+0000] {standard_task_runner.py:72} INFO - Started process 6395 to run task
[2025-10-06T12:10:18.659+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T12:10:19.007+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T12:10:19.014+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T12:10:19.021+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T12:10:19.058+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T12:10:19.106+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T12:10:19.189+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T12:10:19.190+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T12:10:19.237+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T12:10:19.284+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T12:10:19.306+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T12:12:28.113+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T12:12:28.198+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:12:28.233+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:12:28.236+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T12:12:28.302+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T12:12:28.340+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=6454) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T12:12:28.340+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '119', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp66hs7yw5']
[2025-10-06T12:12:28.350+0000] {standard_task_runner.py:105} INFO - Job 119: Subtask wait_for_etl_completion
[2025-10-06T12:12:28.352+0000] {standard_task_runner.py:72} INFO - Started process 6460 to run task
[2025-10-06T12:12:28.575+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T12:12:29.051+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T12:12:29.060+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T12:12:29.067+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T12:12:29.105+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T12:12:29.151+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T12:12:29.254+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T12:12:29.260+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T12:12:29.344+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T12:12:29.415+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T12:12:29.455+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T12:14:38.207+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T12:14:38.270+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:14:38.302+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:14:38.305+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T12:14:38.377+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T12:14:38.421+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '120', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpr8k70l7u']
[2025-10-06T12:14:38.426+0000] {standard_task_runner.py:105} INFO - Job 120: Subtask wait_for_etl_completion
[2025-10-06T12:14:38.420+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=6523) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T12:14:38.432+0000] {standard_task_runner.py:72} INFO - Started process 6526 to run task
[2025-10-06T12:14:38.798+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T12:14:39.291+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T12:14:39.300+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T12:14:39.314+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T12:14:39.350+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T12:14:39.416+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T12:14:39.506+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T12:14:39.508+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T12:14:39.571+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T12:14:39.614+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T12:16:48.738+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T12:16:48.801+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:16:48.829+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:16:48.831+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T12:16:48.884+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T12:16:48.923+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '121', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpmwx1wy2k']
[2025-10-06T12:16:48.935+0000] {standard_task_runner.py:105} INFO - Job 121: Subtask wait_for_etl_completion
[2025-10-06T12:16:48.934+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=6591) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T12:16:48.937+0000] {standard_task_runner.py:72} INFO - Started process 6602 to run task
[2025-10-06T12:16:49.260+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T12:16:49.666+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T12:16:49.670+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T12:16:49.677+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T12:16:49.713+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T12:16:49.779+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T12:16:49.890+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T12:16:49.894+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T12:16:49.939+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T12:16:49.977+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T12:16:49.993+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T12:18:58.275+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T12:18:58.341+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:18:58.375+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:18:58.377+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T12:18:58.434+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T12:18:58.489+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=6663) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T12:18:58.495+0000] {standard_task_runner.py:72} INFO - Started process 6666 to run task
[2025-10-06T12:18:58.493+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '122', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpwjfedbgp']
[2025-10-06T12:18:58.500+0000] {standard_task_runner.py:105} INFO - Job 122: Subtask wait_for_etl_completion
[2025-10-06T12:18:58.735+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T12:18:59.080+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T12:18:59.085+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T12:18:59.093+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T12:18:59.126+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T12:18:59.170+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T12:18:59.252+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T12:18:59.254+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T12:18:59.317+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T12:18:59.367+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T12:18:59.389+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T12:21:06.681+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T12:21:06.741+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:21:06.771+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:21:06.772+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T12:21:06.818+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T12:21:06.843+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=6732) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T12:21:06.845+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '123', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmprc2bvv2c']
[2025-10-06T12:21:06.848+0000] {standard_task_runner.py:72} INFO - Started process 6735 to run task
[2025-10-06T12:21:06.848+0000] {standard_task_runner.py:105} INFO - Job 123: Subtask wait_for_etl_completion
[2025-10-06T12:21:07.017+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T12:21:07.290+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T12:21:07.293+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T12:21:07.300+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T12:21:07.331+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T12:21:07.372+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T12:21:07.447+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T12:21:07.449+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T12:21:07.491+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T12:21:07.528+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T12:21:07.543+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T12:23:16.724+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T12:23:16.813+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:23:16.843+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:23:16.844+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T12:23:16.903+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T12:23:16.938+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=6799) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T12:23:16.939+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '124', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpnu_ybb5b']
[2025-10-06T12:23:16.943+0000] {standard_task_runner.py:72} INFO - Started process 6810 to run task
[2025-10-06T12:23:16.944+0000] {standard_task_runner.py:105} INFO - Job 124: Subtask wait_for_etl_completion
[2025-10-06T12:23:17.138+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T12:23:17.531+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T12:23:17.535+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T12:23:17.542+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T12:23:17.577+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T12:23:17.624+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T12:23:17.764+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T12:23:17.768+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T12:23:17.843+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T12:23:17.886+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T12:23:17.910+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T12:25:26.611+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T12:25:26.681+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:25:26.708+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [queued]>
[2025-10-06T12:25:26.710+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T12:25:26.758+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 08:18:59.872086+00:00
[2025-10-06T12:25:26.787+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=6870) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T12:25:26.789+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T08:18:59.872086+00:00', '--job-id', '125', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpy2vj8o4u']
[2025-10-06T12:25:26.792+0000] {standard_task_runner.py:72} INFO - Started process 6873 to run task
[2025-10-06T12:25:26.793+0000] {standard_task_runner.py:105} INFO - Job 125: Subtask wait_for_etl_completion
[2025-10-06T12:25:26.996+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T08:18:59.872086+00:00 [running]> on host 9687909d01a5
[2025-10-06T12:25:27.289+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T08:18:59.872086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T08:18:59.872086+00:00'
[2025-10-06T12:25:27.293+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T12:25:27.300+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T12:25:27.335+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T08:18:59.872086+00:00 ... 
[2025-10-06T12:25:27.379+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T12:25:27.470+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T12:25:27.475+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T12:25:27.520+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T12:25:27.567+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T12:25:27.584+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
