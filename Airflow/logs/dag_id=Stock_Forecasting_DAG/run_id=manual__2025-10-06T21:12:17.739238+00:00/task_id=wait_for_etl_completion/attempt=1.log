[2025-10-06T21:12:44.631+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T21:12:44.701+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T21:12:17.739238+00:00 [queued]>
[2025-10-06T21:12:44.740+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T21:12:17.739238+00:00 [queued]>
[2025-10-06T21:12:44.743+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T21:12:44.802+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 21:12:17.739238+00:00
[2025-10-06T21:12:44.867+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T21:12:17.739238+00:00', '--job-id', '130', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpf_xsttup']
[2025-10-06T21:12:44.950+0000] {standard_task_runner.py:105} INFO - Job 130: Subtask wait_for_etl_completion
[2025-10-06T21:12:44.866+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=588) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T21:12:45.066+0000] {standard_task_runner.py:72} INFO - Started process 602 to run task
[2025-10-06T21:12:45.185+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T21:12:17.739238+00:00 [running]> on host c1f8128106e6
[2025-10-06T21:12:45.404+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T21:12:17.739238+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T21:12:17.739238+00:00'
[2025-10-06T21:12:45.408+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T21:12:45.414+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T21:12:45.441+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T21:12:17.739238+00:00 ... 
[2025-10-06T21:12:45.474+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T21:12:45.628+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T21:12:45.636+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T21:12:45.918+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T21:12:45.951+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T21:12:45.972+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T21:14:50.024+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T21:14:50.049+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T21:12:17.739238+00:00 [queued]>
[2025-10-06T21:14:50.061+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T21:12:17.739238+00:00 [queued]>
[2025-10-06T21:14:50.062+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T21:14:50.085+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 21:12:17.739238+00:00
[2025-10-06T21:14:50.109+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=663) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T21:14:50.110+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T21:12:17.739238+00:00', '--job-id', '131', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmp1ktuh0_w']
[2025-10-06T21:14:50.112+0000] {standard_task_runner.py:72} INFO - Started process 671 to run task
[2025-10-06T21:14:50.113+0000] {standard_task_runner.py:105} INFO - Job 131: Subtask wait_for_etl_completion
[2025-10-06T21:14:50.214+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T21:12:17.739238+00:00 [running]> on host c1f8128106e6
[2025-10-06T21:14:50.348+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T21:12:17.739238+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T21:12:17.739238+00:00'
[2025-10-06T21:14:50.350+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T21:14:50.354+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T21:14:50.367+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T21:12:17.739238+00:00 ... 
[2025-10-06T21:14:50.384+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T21:14:50.420+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T21:14:50.423+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T21:14:50.466+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T21:14:50.483+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T21:14:50.492+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-10-06T21:22:29.584+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-06T21:22:29.634+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T21:12:17.739238+00:00 [queued]>
[2025-10-06T21:22:29.657+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T21:12:17.739238+00:00 [queued]>
[2025-10-06T21:22:29.658+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-06T21:22:29.717+0000] {taskinstance.py:2888} INFO - Executing <Task(ExternalTaskSensor): wait_for_etl_completion> on 2025-10-06 21:12:17.739238+00:00
[2025-10-06T21:22:29.740+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=687) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-06T21:22:29.740+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Stock_Forecasting_DAG', 'wait_for_etl_completion', 'manual__2025-10-06T21:12:17.739238+00:00', '--job-id', '132', '--raw', '--subdir', 'DAGS_FOLDER/lab1.py', '--cfg-path', '/tmp/tmpo8wutx62']
[2025-10-06T21:22:29.747+0000] {standard_task_runner.py:105} INFO - Job 132: Subtask wait_for_etl_completion
[2025-10-06T21:22:29.745+0000] {standard_task_runner.py:72} INFO - Started process 696 to run task
[2025-10-06T21:22:29.872+0000] {task_command.py:467} INFO - Running <TaskInstance: Stock_Forecasting_DAG.wait_for_etl_completion manual__2025-10-06T21:12:17.739238+00:00 [running]> on host c1f8128106e6
[2025-10-06T21:22:30.248+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Stock_Forecasting_DAG' AIRFLOW_CTX_TASK_ID='wait_for_etl_completion' AIRFLOW_CTX_EXECUTION_DATE='2025-10-06T21:12:17.739238+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-06T21:12:17.739238+00:00'
[2025-10-06T21:22:30.254+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-06T21:22:30.262+0000] {baseoperator.py:405} WARNING - ExternalTaskSensor.execute cannot be called outside TaskInstance!
[2025-10-06T21:22:30.305+0000] {external_task.py:274} INFO - Poking for DAG 'ETL_DAG' on 2025-10-06T21:12:17.739238+00:00 ... 
[2025-10-06T21:22:30.336+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/utils/session.py:97 DeprecationWarning: This method is deprecated and will be removed in future.
[2025-10-06T21:22:30.432+0000] {taskinstance.py:309} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2025-10-06T21:22:30.434+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-06T21:22:30.460+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-06T21:22:30.492+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-10-06T21:22:30.504+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
